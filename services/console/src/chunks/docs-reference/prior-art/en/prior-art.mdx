## Benchmark Tracking Tools

- ### General
  - [Bencher](/pricing/) - Continuous Benchmarking: Catch performance regressions in CI
  - [benchmark-action/github-action-benchmark](https://github.com/benchmark-action/github-action-benchmark) - GitHub Action for continuous benchmarking to keep performance
  - [conbench/conbench](https://github.com/conbench/conbench) - Language-independent Continuous Benchmarking (CB) Framework
  - [Hyperfoil/Horreum](https://github.com/Hyperfoil/Horreum) - Benchmark results repository service
  - [It4innovations/snailwatch](https://github.com/It4innovations/snailwatch) - Continuous performance monitoring service
  - [nyrkio/nyrkio](https://github.com/nyrkio/nyrkio) - Nyrki√∂ is an open source platform for detecting performance changes
  - [seriesci](https://github.com/marketplace/series-ci) - Track any value in CI: bundle size, build time, lines of code, number of dependencies, benchmarks, and much more
  - [smarr/ReBench](https://github.com/smarr/ReBench) - Execute and document benchmarks reproducibly
- ### Benchmark Harness Specific
  - [airspeed-velocity/asv](https://github.com/airspeed-velocity/asv) - Airspeed Velocity: A simple Python benchmarking tool with web-based reporting
  - [bamlab/flashlight](https://github.com/bamlab/flashlight) - Flashlight is a Lighthouse-like tool for mobile apps. No installation required.
  - [benchhub/benchhub](https://github.com/benchhub/benchhub) - A service for running database benchmarks and saving the result
  - [bheisler/criterion.rs](https://github.com/bheisler/criterion.rs) - Statistics-driven benchmarking library for Rust
  - [boa-dev/criterion-compare-action](https://github.com/boa-dev/criterion-compare-action) - Compare the performance of Rust project branches
  - [bobheadxi/gobenchdata](https://github.com/bobheadxi/gobenchdata) - Run Go benchmarks, publish results to an interactive web app, and check for performance regressions in your pull requests
  - [callstack/reassure](https://github.com/callstack/reassure) - Performance testing companion for React and React Native
  - [codingberg/benchgraph](https://github.com/codingberg/benchgraph) - Visualization of Golang benchmark output using Google charts
  - [CodSpeed](https://codspeed.io/) - CodSpeed provides integrated CI tools for software engineering teams to anticipate the impacts of the next delivery on system performance.
  - [Cybench](https://cybench.io) - Continuous performance regression testing for Java CI/CD pipelines
  - [dandavison/chronologer](https://github.com/dandavison/chronologer) - Visualize performance benchmarks over git commit history
  - [dapplion/benchmark](https://github.com/dapplion/benchmark) - JS/TS benchmarking solution to track performance regressions in CI
  - [distributed-system-analysis/pbench](https://github.com/distributed-system-analysis/pbench) - A benchmarking and performance analysis framework
  - [icebob/bench-bot](https://github.com/icebob/bench-bot) - Benchmark runner robot. Continuous benchmarking for benchmarkify the benchmark framework for NodeJS
  - [jsperf/jsperf.com](https://github.com/jsperf/jsperf.com) - jsPerf aims to provide an easy way to create and share test cases, comparing the performance of different JavaScript snippets by running benchmarks.
  - [jumaffre/cimetrics](https://github.com/jumaffre/cimetrics) - Track your metrics in GitHub PR to avoid unwanted regressions
  - [knqyf263/cob](https://github.com/knqyf263/cob) - Continuous Benchmark for Go Project
  - [moditect/jfrunit](https://github.com/moditect/jfrunit) - A JUnit extension for asserting JDK Flight Recorder events
  - [NimbleDroid](https://nimbledroid.com/) - Functional Performance Testing for Android & iOS
  - [novadiscovery/benchgraph](https://github.com/novadiscovery/benchgraph) - A lightewight tool for visualizing your benchmarks history
  - [OctoPerf](https://octoperf.com/) - Simplify your load testing experience
  - [ocurrent/current-bench](https://github.com/ocurrent/current-bench) - Experimental continuous benchmarking infrastructure using OCurrent pipelines
  - [OpenBenchmarking.org](https://openbenchmarking.org/) - Storage of Phoronix Test Suite benchmark result data (including optional system logs, etc)
  - [OpenEBench](https://openebench.bsc.es/) - OpenEBench is the ELIXIR gateway to benchmarking communities, software monitoring, and quality metrics for life sciences tools and workflows.
  - [Orijtech bencher](https://bencher.orijtech.com) - Continuous benchmarking for the Go programming language
  - [Perfbench](https://perfbench.com/) - Perfbench is an interactive online C++ code profiling tool.
  - [Performance Analysis](https://www.emergetools.com/#performance-analysis) - Diagnose & prevent performance regressions
  - [python/codespeed](https://github.com/python/codespeed) - A fork of Codespeed that includes the instances run at https://speed.python.org/ and https://speed.pypy.org
  - [tobami/codespeed](https://github.com/tobami/codespeed) - A web application to monitor and analyze the performance of your code
  - [trytouca/trytouca](https://github.com/trytouca/trytouca) - Continuous Regression Testing for Engineering Teams
  - [Unity-Technologies/PerformanceBenchmarkReporter](https://github.com/Unity-Technologies/PerformanceBenchmarkReporter) - Establish benchmark samples and measurements using the Performance Testing package, then use these benchmark values to compare subsequent performance test results in an html output utilizing graphical visualizations
- ### Web Specific
  - [Contentsquare](https://contentsquare.com/product-tour-speed-analysis/) - Speed Analysis is not only about Synthetic Monitoring but also offers powerful Real User Monitoring capabilities, a great fit for brands leading the way on customer experience across the world.
  - [Iron/Out](https://www.iron-out.io) - Faster websites equals better business results: improve user experience, increase conversion rate and page experience ranking, lower the bounce rate
  - [MeasureWorks](https://measureworks.nl) - Track user behavior with End-2-End observability to continuously optimize your online performance
  - [SpeedCurve](https://www.speedcurve.com) - See how people experience the speed of your website, then identify and fix performance issues
  - [ubenchan/frontend](https://github.com/ubenchan/frontend) - Beautiful browser benchmarks
  - [WebPageTest](https://www.webpagetest.org) - Run a free website speed test from around the globe using real browsers at consumer connection speeds with detailed optimization recommendations
- ### Project Specific
  - [apache/arrow-datafusion](https://github.com/apache/arrow-datafusion/pull/9461) - A `/benchmark` GitHub command to compare benchmark between base and PR commits
  - [BrowserBench](https://browserbench.org) - Speedometer is a browser benchmark that measures the responsiveness of web applications
  - [corecheck/corecheck](https://github.com/corecheck/corecheck) - Test coverage and more for Bitcoin Core including continuous benchmarking
  - [deno.land benchmarks](https://deno.land/benchmarks) - As part of Deno's continuous integration and testing pipeline we measure the performance of certain key metrics of the runtime. You can view these benchmarks here.
  - [diesel-rs/metrics](https://github.com/diesel-rs/metrics) - The numbers collected by diesel continuous scheduled benchmark actions to track changes over time
  - [Elasticsearch Benchmarks](https://elasticsearch-benchmarks.elastic.co) - The results of the Elasticsearch nightly benchmarks based on the main branch as of that point in time
  - [Feldera Benchmarks](https://benchmarks.feldera.io/) - Benchmarks for Feldera
  - [golang/benchmarks](https://github.com/golang/benchmarks) - Benchmarks for [the Go perf dashboard](https://perf.golang.org/dashboard/)
  - [Google Chrome V8](https://github.com/v8/v8/tree/main/test/benchmarks/csuite) - CSuite: Local benchmarking for V8 performance analysis
  - [lampepfl/bench-data](https://github.com/lampepfl/bench-data) - Continuous benchmarking data for [Dotty Benchmarks](https://dotty-bench.epfl.ch)
  - [Lucene Nightly Benchmarks](https://people.apache.org/~mikemccand/lucenebench) - Each night, an automated Python tool checks out the Lucene/Solr trunk source code and runs multiple benchmarks
  - [Myoldmopar/EnergyPlusBuildResults](https://github.com/Myoldmopar/EnergyPlusBuildResults) - Build, test, and performance results [dashboard for EnergyPlus](https://myoldmopar.github.io/EnergyPlusBuildResults/index.html)
  - [OpenTelemetry Benchmarks](https://opentelemetry.io/docs/collector/benchmarks/) - The OpenTelemetry Collector runs load tests on every commit to [the `opentelemetry-collector-contrib` repository](https://github.com/open-telemetry/opentelemetry-collector-contrib)
  - [parse-community/benchmark](https://github.com/parse-community/benchmark) - Parse Server Continuous Benchmark
  - [python/pyperformance](https://github.com/python/pyperformance) - Python Performance Benchmark Suite
  - [pytorch/benchmark](https://github.com/pytorch/benchmark) - TorchBench is a collection of open source benchmarks used to evaluate PyTorch performance.
  - [PyPy Speed Center](https://speed.pypy.org) - A fork of Codespeed of PyPy
  - [Python Speed Center](https://speed.python.org) - A fork of Codespeed for Python
  - [rust-lang/rustc-perf](https://github.com/rust-lang/rustc-perf) - Website for graphing performance of rustc
  - [Shopify/yjit-bench](https://github.com/Shopify/yjit-bench) - Set of benchmarks for the YJIT CRuby JIT compiler and other Ruby implementations seen at [speed.yjit.org](https://speed.yjit.org/)
  - [Skia Perf](https://skia.org/docs/dev/testing/skiaperf/) - [Skia Perf](https://perf.skia.org) is a web application for analyzing and viewing performance metrics produced by Skia's [testing infrastructure](https://github.com/google/skia-buildbot/tree/main/perf)
  - [Supabench](https://github.com/supabase/benchmarks) - App by Supabase team to run benchmarks automatically in CI
  - [Vitess Are We Fast Yet](https://benchmark.vitess.io/) - Automated benchmarking system that tests Vitess's performance on a nightly basis
  - [rustls/rustls-bench-app](https://github.com/rustls/rustls-bench-app) - Continuous benchmarking for the Rustls project
  - [Zen Browser Benchmarks](https://docs.zen-browser.app/benchmarks) - Performance Benchmarks for the Zen Browser
  - [ziglang/gotta-go-fast](https://github.com/ziglang/gotta-go-fast) - Performance Tracking for Zig

> üê∞ A special thank you to [Continuous Benchmark](https://github.com/marketplace/actions/continuous-benchmark)!
> Some of their test files are used for our [Benchmark Harness Adapters](https://bencher.dev/docs/explanation/adapters/).

## Benchmark Tracking Posts

- ### Microsoft
  - [Performance regression tests at Microsoft Security](https://devblogs.microsoft.com/premier-developer/performance-regression-tests-at-microsoft-security/)
- ### Facebook
  - [Mobile performance: Tooling infrastructure at Facebook](https://engineering.fb.com/2015/04/10/developer-tools/mobile-performance-tooling-infrastructure-at-facebook/)
  - [BrowserLab: Automated regression detection for the web](https://engineering.fb.com/2016/08/31/web/browserlab-automated-regression-detection-for-the-web/)
  - [MobileLab: Highly accurate testing to prevent mobile performance regressions](https://engineering.fb.com/2018/10/19/android/mobilelab/)
- ### Apple
  - [WebKit Regression Testing](https://webkit.org/regression-testing/)
  - [WebKit's no performance regression policy](https://nicoverbruggen.be/blog/webkit-no-regression-policy)
- ### Amazon
  - [Performance Efficiency: Benchmark existing workloads](https://web.archive.org/web/20230611135508/https://docs.aws.amazon.com/wellarchitected/latest/framework/perf_performing_architecture_benchmark.html)
- ### Netflix
  - [Fixing Performance Regressions Before they Happen](https://netflixtechblog.com/fixing-performance-regressions-before-they-happen-eab2602b86fe)
- ### Google
  - [Chrome: Addressing Performance Regressions](https://chromium.googlesource.com/chromium/src/+/master/docs/speed/addressing_performance_regressions.md)
  - [Android Developers: Run benchmarks in Continuous Integration](https://developer.android.com/topic/performance/benchmarking/benchmarking-in-ci)
  - [Flutter/Skia: Detecting Benchmark Regression](https://bitworking.org/news/2014/11/detecting-benchmark-regressions/)
  - [Android Developers: Fighting regressions with Benchmarks in CI](https://medium.com/androiddevelopers/fighting-regressions-with-benchmarks-in-ci-6ea9a14b5c71)
- ### Dropbox
  - [Athena: Our automated build health management system](https://dropbox.tech/infrastructure/athena-our-automated-build-health-management-system)
  - [Keeping sync fast with automated performance regression detection](https://dropbox.tech/infrastructure/keeping-sync-fast-with-automated-performance-regression-detectio)
- ### Elastic
  - [How we perform continuous performance testing on Enterprise Search](https://www.elastic.co/blog/how-to-use-continuous-performance-testing-for-enterprise-search)
- ### MongoDB
  - [Reducing Variability in Performance Tests on EC2: Setup and Key Results](https://www.mongodb.com/blog/post/reducing-variability-performance-tests-ec2-setup-key-results)
  - [Using Change Point Detection to Find Performance Regressions](https://www.mongodb.com/blog/post/using-change-point-detection-find-performance-regressions)
  - [Creating a virtuous cycle in performance testing](https://www.tricentis.com/resources/virtuous-cycle-performance-testing-pac21)
  - [The Use of Change Point Detection to Identify Software Performance Regressions in a Continuous Integration System](https://dl.acm.org/doi/abs/10.1145/3358960.3375791) ([video](https://www.youtube.com/watch?v=rSBgcMFPkHU))
  - [Automated system performance testing at MongoDB](https://dl.acm.org/doi/abs/10.1145/3395032.3395323)
  - [Creating a Virtuous Cycle in Performance Testing at MongoDB](https://dl.acm.org/doi/10.1145/3427921.3450234) ([video](https://www.youtube.com/watch?v=nmTQHFa0upI))
  - [Automated Triage of Performance Change Points Using Time Series Analysis and Machine Learning: Data Challenge Paper](https://dl.acm.org/doi/10.1145/3491204.3527486)
  - [Characterizing and Triaging Change Points](https://dl.acm.org/doi/10.1145/3491204.3527487)
  - [Beware of the Interactions of Variability Layers When Reasoning about Evolution of MongoDB](https://dl.acm.org/doi/10.1145/3491204.3527489)
  - [Change Point Detection for MongoDB Time Series Performance Regression](https://dl.acm.org/doi/10.1145/3491204.3527488)
  - [Performance Testing at MongoDB](https://youtu.be/elRLJ997p6A?si=2oZUut28bOhyEhKE)
- ### Academic
  - [Producing Wrong Data Without Doing Anything Obviously Wrong!](https://users.cs.northwestern.edu/~robby/courses/322-2013-spring/mytkowicz-wrong-data.pdf)
  - [Locating Performance Regression Root Causes in the Field Operations of Web-Based Systems: An Experience Report](https://ieeexplore.ieee.org/document/9629300)
  - [Stabilizer: Statistically Sound Performance Evaluation](https://emeryberger.com/research/stabilizer/)
  - [A Nonparametric Approach for Multiple Change Point Analysis of Multivariate Data](https://arxiv.org/pdf/1306.4933.pdf)
  - [Automated Detection of Performance Regressions Using Regression Models on Clustered Performance Counters](https://www.researchgate.net/publication/281117799_Automated_Detection_of_Performance_Regressions_Using_Regression_Models_on_Clustered_Performance_Counters)
  - [Robust benchmarking in noisy environments](https://arxiv.org/abs/1608.04295)
  - [Virtual Machine Warmup Blows Hot and Cold](https://soft-dev.org/pubs/html/barrett_bolz-tereick_killick_mount_tratt__virtual_machine_warmup_blows_hot_and_cold_v6/)
  - [BenchHub: store database benchmark result in database](https://escholarship.org/uc/item/1t8436b6)
  - [Continuous Benchmarking: Using System Benchmarking in Build Pipelines](https://www.researchgate.net/publication/333918034_Continuous_Benchmarking_Using_System_Benchmarking_in_Build_Pipelines)
  - [Towards Continuous Benchmarking: An Automated Performance Evaluation Framework for High Performance Software](https://dl.acm.org/doi/10.1145/3324989.3325719)
  - [Duet Benchmarking: Improving Measurement Accuracy in the Cloud](https://arxiv.org/abs/2001.05811)
  - [Search-based detection of code changes introducing performance regression](https://www.sciencedirect.com/science/article/abs/pii/S2210650222000712)
  - [Hunter: Using Change Point Detection to Hunt for Performance Regressions](https://dl.acm.org/doi/abs/10.1145/3578244.3583719)
  - [ElastiBench: Scalable Continuous Benchmarking on Cloud FaaS Platforms](https://arxiv.org/html/2405.13528v1)
  - [Increasing Efficiency and Result Reliability of Continuous Benchmarking for FaaS Applications](https://arxiv.org/abs/2405.15610)
- ### Others
  - [Accurate and efficient software microbenchmarks](https://www.youtube.com/watch?v=BFISG3LY9UQ)
  - [Are Benchmarks From Cloud CI Services Reliable?](https://bheisler.github.io/post/benchmarking-in-the-cloud/)
  - [Are your memory-bound benchmarking timings normally distributed?](https://lemire.me/blog/2023/04/06/are-your-memory-bound-benchmarking-timings-normally-distributed/)
  - [Automated performance regression testing with Reassure](https://www.youtube.com/watch?v=NR_cYq7oYpc)
  - [automatically prevent performance regressions](https://stackoverflow.com/questions/19713319/automatically-prevent-performance-regressions)
  - [Automating Speed: A Proven Approach to Preventing Performance Regressions in Kafka Streams](https://www.confluent.io/events/kafka-summit-london-2024/automating-speed-a-proven-approach-to-preventing-performance-regressions-in/)
  - [Autonomously Finding Performance Regressions In The Linux Kernel](https://www.phoronix.com/review/linux_perf_regressions)
  - [Benchmarking C++ Code at CppCon 2015](https://www.youtube.com/watch?v=zWxSZcpeS8Q)
  - [Building an Open Source, Continuous Benchmark System](https://wolfv.medium.com/building-an-open-source-continuous-benchmark-system-717839093962)
  - [CI for performance: Reliable benchmarking in noisy environments](https://pythonspeed.com/articles/consistent-benchmarking-in-ci/)
  - [Compare and optimize your code with Datadog Profile Comparison](https://www.datadoghq.com/blog/code-optimization-datadog-profile-comparison/)
  - [Continuous Benchmarking for OCaml Projects](https://watch.ocaml.org/videos/watch/1c994370-1aaa-4db6-b901-d762786e4904)
  - [Continuous benchmarking for rustls](https://ochagavia.nl/blog/continuous-benchmarking-for-rustls/)
  - [Continuous Benchmarks on a Budget](https://blog.martincostello.com/continuous-benchmarks-on-a-budget/)
  - [Continuous Performance Regression Testing for CI/CD](https://www.meshiq.com/continuous-performance-regression-testing-for-ci-cd/)
  - [Created GitHub Action for continuous benchmarking](https://rhysd-hatenablog-com.translate.goog/entry/2019/11/11/131505?_x_tr_sl=ja&_x_tr_tl=en&_x_tr_hl=en&_x_tr_pto=wapp)
  - [Demanding the impossible rigorous database benchmarking](https://www.youtube.com/watch?v=Nt6IdiEb0rU)
  - [Exploring the Rust compiler benchmark suite](https://kobzol.github.io/rust/rustc/2023/08/18/rustc-benchmark-suite.html)
  - [Get a performance score for your app](https://www.youtube.com/watch?v=q-_rMpoCs3A)
  - [Hardware performance counter support (via `rdpmc`)](https://github.com/eddyb/hackmd-notes/blob/master/measureme-rdpmc.md)
  - [Is GitHub Actions suitable for running benchmarks?](https://labs.quansight.org/blog/2021/08/github-actions-benchmarks)
  - [Lighthouse for mobile apps](https://www.youtube.com/watch?v=XO8O1iL4Rxg)
  - [Measuring and Improving React Native Performance](https://www.youtube.com/watch?v=5Q3VCgKV0GE)
  - [Microbenchmarking calls for idealized conditions](https://lemire.me/blog/2018/01/16/microbenchmarking-calls-for-idealized-conditions/)
  - [Minimum Times Tend to Mislead When Benchmarking](https://tratt.net/laurie/blog/2019/minimum_times_tend_to_mislead_when_benchmarking.html)
  - [Paired benchmarking. How to measure performance](https://www.bazhenov.me/posts/paired-benchmarking/)
  - [Performance engineering requires stable benchmarks](https://buttondown.com/nelhage/archive/f6e8eddc-b96c-4e66-a648-006f9ebb6678)
  - [Performance in Continuous Integration](https://www.dynatrace.com/resources/ebooks/javabook/performance-in-continuous-integration/)
  - [Performance Regression Testing](https://octoperf.com/blog/2020/11/16/performance-regression-testing)
  - [Performance testing in CI: Let's break the build!](https://www.speedcurve.com/blog/performance-testing-in-ci-lets-break-the-build/)
  - [Performance Testing in the CI/CD Pipeline](https://www.subject-7.com/performance-testing-in-the-ci-cd-pipeline/)
  - [Performance-Regression Pitfalls Every Project Should Avoid](https://www.eetimes.eu/performance-regression-pitfalls-every-project-should-avoid/)
  - [Regression Testing of Performance - SmartBear TestComplete](https://www.youtube.com/watch?v=_L0BsKKYT_4)
  - [Rust Performance Testing on Travis CI](https://beachape.com/blog/2016/11/02/rust-performance-testing-on-travis-ci/)
  - [Storing Continuous Benchmarking Data in Prometheus](https://www.youtube.com/watch?v=1Yj2pSfsu8I)
  - [The mean misleads: why the minimum is the true measure of a function‚Äôs run time](https://betterprogramming.pub/the-mean-misleads-why-the-minimum-is-the-true-measure-of-a-functions-run-time-47fa079075b0)
  - [Towards Continuous Performance Regression Testing](https://www.morling.dev/blog/towards-continuous-performance-regression-testing)

## Benchmark Comparisons

- [BurntSushi/rebar](https://github.com/BurntSushi/rebar) - A biased barometer for gauging the relative speed of some regex engines on a curated set of tasks.
- [CH-benCHmark](https://db.in.tum.de/research/projects/CHbenCHmark/index.shtml) - Operational and real-time Business Intelligence (BI) mixed workload SQL benchmarks
- [ClickBench](https://benchmark.clickhouse.com/) - A Benchmark For Analytical DBMS
- [denosaurs/bench](https://github.com/denosaurs/bench) - Comparing deno & node HTTP frameworks
- [diesel-rs/diesel_bench](https://github.com/diesel-rs/diesel/tree/master/diesel_bench) - A benchmark suite for relational database connection crates in Rust
- [HewlettPackard/netperf](https://github.com/HewlettPackard/netperf) - Netperf is a benchmark that can be used to measure the performance of many different types of networking. It provides tests for both unidirectional throughput, and end-to-end latency
- [krausest/js-framework-benchmark](https://github.com/krausest/js-framework-benchmark) - A comparison of the performance of a few popular javascript frameworks
- [parttimenerd/temci](https://github.com/parttimenerd/temci) - An advanced benchmarking tool
- [PerfKit Benchmarker (PKB)](https://github.com/GoogleCloudPlatform/PerfKitBenchmarker) - A set of benchmarks to measure and compare cloud offerings. The benchmarks use default settings to reflect what most users will see.
- [Programming Language Benchmarks](https://programming-language-benchmarks.vercel.app/) - Yet another implementation of computer language benchmarks game
- [rosetta-rs/argparse-rosetta-rs](https://github.com/rosetta-rs/argparse-rosetta-rs) - Comparison of Rust argparse APIs
- [rosetta-rs/hashing-rosetta-rs](https://github.com/rosetta-rs/hashing-rosetta-rs) - Comparison of Rust hash comparison vs direct string comparison
- [rosetta-rs/md-rosetta-rs](https://github.com/rosetta-rs/md-rosetta-rs) - Comparison of Rust Markdown APIs
- [rosetta-rs/parse-rosetta-rs](https://github.com/rosetta-rs/parse-rosetta-rs) - Comparison of Rust parser APIs
- [rosetta-rs/string-rosetta-rs](https://github.com/rosetta-rs/string-rosetta-rs) - Comparison of Rust string types
- [rosetta-rs/template-benchmarks-rs](https://github.com/rosetta-rs/template-benchmarks-rs) - Comparison of Rust template engines
- [Standard Performance Evaluation Corporation (SPEC)](https://www.spec.org/benchmarks.html) - A non-profit consortium that establishes and maintains standardized benchmarks and performance evalutation tools for new generations of computing systems
- [TechEmpower/FrameworkBenchmarks](https://github.com/TechEmpower/FrameworkBenchmarks) - In the following tests, we have measured the performance of several web application platforms, full-stack frameworks, and micro-frameworks (collectively, "frameworks").
- [timescale/tsbs](https://github.com/timescale/tsbs) - Time Series Benchmark Suite, a tool for comparing and evaluating databases for time series data
- [The Computer Language Benchmarks Game](https://benchmarksgame-team.pages.debian.net/benchmarksgame/index.html) - Which programming language is fastest?
- [TPC](https://www.tpc.org/information/benchmarks5.asp) - Benchmarking and load testing for the worlds most popular databases supporting Oracle Database, Microsoft SQL Server, IBM Db2, PostgreSQL, MySQL and MariaDB
- [Top500](https://www.top500.org) - Ranks and details the 500 most powerful non-distributed computer systems in the world

## Benchmark Harnesses

- ### Android
  - [Macrobenchmark](https://developer.android.com/topic/performance/benchmarking/macrobenchmark-overview) - Writing a Macrobenchmark
  - [Microbenchmark](https://developer.android.com/topic/performance/benchmarking/microbenchmark-overview) - Microbenchmark Overview
- ### C
  - [akopytov/sysbench](https://github.com/akopytov/sysbench) - Scriptable database and system performance benchmark
  - [gormanm/mmtests](https://github.com/gormanm/mmtests) - Benchmarking framework primarily aimed at Linux kernel testing
  - [Linux kernel perf bench](https://perf.wiki.kernel.org/index.php/Tutorial#Benchmarking_with_perf_bench) - This command includes a number of multi-threaded microbenchmarks to exercise different subsystems in the Linux kernel and system calls.
  - [LinuxPerfStudy/LEBench](https://github.com/LinuxPerfStudy/LEBench) - An analysis of performance evolution of Linux's core operations
  - [Phoronix Test Suite](https://www.phoronix-test-suite.com) - Open-Source, Automated Benchmarking
  - [RRZE-HPC/likwid](https://github.com/RRZE-HPC/likwid) - Performance monitoring and benchmarking suite
- ### C++
  - [catchorg/Catch2](https://github.com/catchorg/Catch2) - A modern, C++-native, test framework for unit-tests, TDD, and BDD - using C++14, C++17, and later
  - [DigitalInBlue/Celero](https://github.com/DigitalInBlue/Celero) - C++ Benchmark Authoring Library/Framework
  - [facebook/folly/Benchmark.h](https://github.com/facebook/folly/blob/main/folly/docs/Benchmark.md) - Provides a simple framework for writing and executing benchmarks
  - [google/benchmark](https://github.com/google/benchmark) - A microbenchmark support library for C++
  - [iboB/picobench](https://github.com/iboB/picobench) - A micro microbenchmarking library for C++11 in a single header file
  - [ivafanas/sltbench](https://github.com/ivafanas/sltbench) - C++ benchmark tool. Practical, stable and fast performance testing framework.
  - [libnonius/nonius](https://github.com/libnonius/nonius) - A C++ micro-benchmarking framework
- ### C#
  - [donet/BenchmarkDotNet](https://github.com/dotnet/BenchmarkDotNet) - Powerful .NET library for benchmarking
  - [Unity-Technologies/PerformanceBenchmarkReporter](https://github.com/Unity-Technologies/PerformanceBenchmarkReporter) - Establish benchmark samples and measurements using the Performance Testing package, then use these benchmark values to compare subsequent performance test results in an html output utilizing graphical visualizations
  - [xunit/xunit](https://github.com/xunit/xunit) - xUnit.net is a free, open source, community-focused unit testing tool for .NET
- ### Elixir
  - [alco/benchfella](https://github.com/alco/benchfella) -  Microbenchmarking tool for Elixir
  - [bencheeorg/benchee](https://github.com/bencheeorg/benchee) - Easy and extensible benchmarking in Elixir providing you with lots of statistics!
- ### Functions as a Service (FaaS)
  - [vhive-serverless/STeLLAR](https://github.com/vhive-serverless/STeLLAR) - STeLLAR: Open-source framework for serverless clouds benchmarking
- ### Go
  - [Benchmarks](https://pkg.go.dev/testing#hdr-Benchmarks) - Go test benchmarks
- ### Haskell
  - [haskell/criterion](https://github.com/haskell/criterion) - A powerful but simple library for measuring the performance of Haskell code
- ### Java
  - [moditect/jfrunit](https://github.com/moditect/jfrunit) - A JUnit extension for asserting JDK Flight Recorder events
  - [openjdk/jmh](https://github.com/openjdk/jmh) - JMH is a Java harness for building, running, and analyzing nano/micro/milli/macro benchmarks written in Java and other languages targeting the JVM
- ### JavaScript
  - [bestiejs/benchmark.js](https://github.com/bestiejs/benchmark.js) - A benchmarking library. As used on jsPerf.com
  - [callstack/reassure](https://github.com/callstack/reassure) - Performance testing companion for React and React Native
  - [console.time](https://developer.mozilla.org/en-US/docs/Web/API/console/time)/[console.timeEnd](https://developer.mozilla.org/en-US/docs/Web/API/console/timeEnd) - A method to start/stop a timer you can use to track how long an operation takes
  - [deno bench](https://docs.deno.com/runtime/manual/tools/benchmarker) - Deno has a built-in benchmark runner that you can use for checking performance of JavaScript or TypeScript code.
  - [evanwashere/mitata](https://github.com/evanwashere/mitata) - cross-runtime benchmarking lib and cli
  - [Node.js Performance Measurement API](https://nodejs.org/api/perf_hooks.html) - This module provides an implementation of a subset of the [W3C Web Performance APIs](https://w3c.github.io/perf-timing-primer/) as well as additional APIs for Node.js-specific performance measurements.
  - [RafaelGSS/bench-node](https://github.com/RafaelGSS/bench-node) - The `bench-node` module gives the ability to measure performance of JavaScript code.
  - [ShogunPanda/cronometro](https://github.com/ShogunPanda/cronometro) - Simple benchmarking suite powered by HDR histograms.
  - [tinylibs/tinybench](https://github.com/tinylibs/tinybench) - A simple, tiny and lightweight benchmarking library!
  - [v8/web-tooling-benchmark](https://github.com/v8/web-tooling-benchmark) - JavaScript benchmark for common web developer workloads
  - [vitest bench](https://vitest.dev/api/#bench) - `vitest bench` uses tinybench library under the hood
  - [yamiteru/isitfast](https://github.com/yamiteru/isitfast) - A modular benchmarking library with V8 warmup and cpu/ram denoising for the most accurate and consistent results.
- ### Julia
  - [JuliaCI/BenchmarkTools.jl](https://github.com/JuliaCI/BenchmarkTools.jl) - A benchmarking framework for the Julia language
- ### Python
  - [airspeed-velocity/asv](https://github.com/airspeed-velocity/asv) - Airspeed Velocity: A simple Python benchmarking tool with web-based reporting
  - [ionelmc/pytest-benchmark](https://github.com/ionelmc/pytest-benchmark) - py.test fixture for benchmarking code
  - [timeit](https://docs.python.org/3/library/timeit.html) - This module provides a simple way to time small bits of Python code
- ### Ruby
  - [ruby/benchmark](https://github.com/ruby/benchmark) - Methods for benchmarking Ruby code, giving detailed reports on the time taken for each task
- ### Rust
  - [bazhenov/tango](https://github.com/bazhenov/tango) - Rust pairwise microbenchmarking harness
  - [bheisler/criterion.rs](https://github.com/bheisler/criterion.rs) - Statistics-driven benchmarking library for Rust
  - [bheisler/iai](https://github.com/bheisler/iai) - Experimental one-shot benchmarking/profiling harness for Rust
  - [bluss/bencher](https://github.com/bluss/bencher) - bencher is just a port of the libtest (unstable) benchmark runner to Rust stable releases. `cargo bench` on stable. "Not a better bencher!" = No feature development. Go build a better stable benchmarking library.
  - [BurntSushi/cargo-benchcmp](https://github.com/BurntSushi/cargo-benchcmp) - A small utility to compare Rust micro-benchmarks
  - [iai-callgrind/iai-callgrind](https://github.com/iai-callgrind/iai-callgrind) - High-precision and consistent benchmarking framework/harness for Rust
  - [jbreitbart/criterion-perf-events](https://github.com/jbreitbart/criterion-perf-events) - A plugin for Criterion.rs to measure Linux perf events
  - [libtest bench](https://doc.rust-lang.org/rustc/tests/index.html#benchmarks) - The libtest harness supports running benchmarks for functions annotated with the `#[bench]` attribute. Benchmarks are currently unstable, and only available on the nightly channel.
  - [ThijsRay/coppers](https://github.com/ThijsRay/coppers) - Coppers is a custom test harnass for Rust that measures the energy usage of your test suite.
  - [nvzqz/divan](https://github.com/nvzqz/divan) - Comfy benchmarking for Rust projects
  - [sarah-ek/diol](https://github.com/sarah-ek/diol) - diol is a benchmarking library for Rust.
- ### Shell
  - [Gabriella439/bench](https://github.com/Gabriella439/bench) -  Command-line benchmark tool
  - [sharkdp/hyperfine](https://github.com/sharkdp/hyperfine) - A command-line benchmarking tool
- ### SQL
  - [ClickHouse/ClickBench](https://github.com/ClickHouse/ClickBench) - ClickBench: a Benchmark For Analytical Databases
  - [TPC-Council/HammerDB](https://github.com/TPC-Council/HammerDB) - HammerDB Database Load Testing and Benchmarking Tool
- ### Swift
  - [apple/swift](https://github.com/apple/swift/tree/main/benchmark) - The Swift Benchmark Suite
  - [google/swift-benchmark](https://github.com/google/swift-benchmark) - A swift library to benchmark code snippets
